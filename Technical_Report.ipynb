{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stroke Classification Project Report\n",
    "### Authors: Nelly Alger, Maya Fleming\n",
    "### CPSC 322 Spring 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This project implements data mining and classification of a dataset containing instances of patients who have or have not had a stroke. We performed an exploratory data analysis, which helped us identify the most relevant attributes. We then implemented four classifiers using a 10-fold cross validation to gain a balanced understanding of the classifiers' performances.\n",
    "\n",
    "<span style=\"color:red\">TODO: FINDINGS</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "\n",
    "* Information about the dataset itself, e.g., the attributes and attribute types, the number of instances, and the attribute being used as the label.\n",
    "* Relevant summary statistics about the dataset.\n",
    "\n",
    "##### ATTRIBUTE INFORMATION:\n",
    "* id: unique identifier\n",
    "    * integer\n",
    "* gender: \"Male\", \"Female\" or \"Other\"\n",
    "    * string categorical: ['Female', 'Male', 'Other'] \n",
    "* age: age of the patient\n",
    "    * float continuous -- we discretized into bins of 10 years\n",
    "* hypertension: 0 if the patient doesn't have hypertension, 1 if the patient has hypertension\n",
    "    * float categorical \n",
    "* heart_disease: 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease\n",
    "    * float categorical\n",
    "* ever_married: \"No\" or \"Yes\"\n",
    "    * string categorical\n",
    "* work_type: \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\"\n",
    "    * string categorical\n",
    "* Residence_type: \"Rural\" or \"Urban\"\n",
    "    * string categorical\n",
    "* avg_glucose_level: average glucose level in blood\n",
    "    * float continuous -- discretized into 6 bins\n",
    "* bmi: body mass index\n",
    "    * float continuous -- discretized into bins of 10\n",
    "* smoking_status: \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"\n",
    "    * string categorical\n",
    "    * Note: \"Unknown\" in smoking_status means that the information is unavailable for this patient\n",
    "* stroke: 1 if the patient had a stroke or 0 if not\n",
    "    * float categorical\n",
    "\n",
    "##### DATASET CLEANING\n",
    "* To begin, we deleted the ID attribute as it was not relevant or necessary to classification\n",
    "* The dataset contained **5110** instances, and we removed the instances with \"NA\" values since this number was so high, leaving 4909 instances\n",
    "* We then downsized the data because of how imbalanced it was. Instances with a stroke (1) were much more rare, only 209 out of the 5110\n",
    "    * This makes classification difficult because classifiers are likely to classify any unseen instances as stroke (1)\n",
    "    * We downsized to a total of **1000** instances, 791 randomly selected of the non-stroke (0) instances\n",
    "\n",
    "Data cleaning code located below (file: data_cleaning_work.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length before 'NA' values removed: 5110\n",
      "length after 'NA' values removed: 4909\n",
      "amount of non-strokes with no 'NA' rows: 4700\n",
      "amount of strokes with no 'NA' rows: 209\n",
      "num of strokes with unknown smoking status: 29\n",
      "length of downsized non-stroke data: 791\n",
      "length of all downsized data: 1000\n",
      "length of final_data 1000\n",
      "-----SAVED DOWNSIZED DATA-----\n",
      "non-stroke amount: 791\n",
      "stroke amount: 209\n",
      "-----saved discretized columns-----\n",
      "-----saved numerical final data-----\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import data_cleaning_work\n",
    "importlib.reload(data_cleaning_work)\n",
    "\n",
    "random_seed = 0\n",
    "data_cleaning_work.clean_data(random_seed, \"input_data/stroke-data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DATA VISUALIZATION\n",
    "* Data visualizations highlighting important/interesting aspects of your dataset. Visualizations may include frequency distributions, comparisons of attributes (scatterplot, multiple frequency diagrams), box and whisker plots, etc. The goal is not to include all possible diagrams, but instead to select and highlight diagrams that provide insight about the dataset itself.\n",
    "* Note that this section must describe the above (in paragraph form) and not just provide diagrams and statistics. Also, each figure included must have a figure caption (Figure number and textual description) that is referenced from the text (e.g., “Figure 2 shows a frequency diagram for ...”).\n",
    "\n",
    "The following data visualizations helped us determine which attributes were most relevant to classification:\n",
    "\n",
    "<span style=\"color:red\">TODO: insert graphs</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data Classification\n",
    "* This section should describe the classification approach you developed and its performance. \n",
    "* Explain what techniques you used, briefly how you designed and implemented the classifiers, how you evaluated your classifiers’ predictive ability, and how well the classifiers performed.\n",
    "* Thoroughly describe how you evaluated performance, the comparison results, and which classifier is “best”. \n",
    "* Create a Flask web app with this “best” classifier deployed with an API interface. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "attribute names: ['gender', 'age', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'avg_glucose_level', 'bmi', 'smoking_status', 'stroke']\n",
      "classes: [0.0, 1.0]\n",
      "num instances of class 0.0 : 791\n",
      "num instances of class 1.0 : 209\n",
      "\n",
      "=====================\n",
      "kNN Classifier (5 neighbors)\n",
      "=====================\n",
      "Accuracy:\t 0.75\n",
      "Error Rate:\t 0.25\n",
      "Precision:\t 0.79\n",
      "Recall:\t\t 0.93\n",
      "F1 measure:\t 0.86\n",
      "Confusion matrix:\n",
      "       0.0    1.0\n",
      "--  -----  -----\n",
      " 0    734     57\n",
      " 1    191     18\n",
      "\n",
      "=====================\n",
      "Naive Bayes\n",
      "=====================\n",
      "Accuracy:\t 0.79\n",
      "Error Rate:\t 0.21\n",
      "Precision:\t 0.79\n",
      "Recall:\t\t 1.0\n",
      "F1 measure:\t 0.88\n",
      "Confusion matrix:\n",
      "       0.0    1.0\n",
      "--  -----  -----\n",
      " 0    789      2\n",
      " 1    209      0\n",
      "\n",
      "=====================\n",
      "Decision Tree\n",
      "=====================\n",
      "Accuracy:\t 0.79\n",
      "Error Rate:\t 0.21\n",
      "Precision:\t 0.79\n",
      "Recall:\t\t 0.99\n",
      "F1 measure:\t 0.88\n",
      "Confusion matrix:\n",
      "       0.0    1.0\n",
      "--  -----  -----\n",
      " 0    787      4\n",
      " 1    209      0\n"
     ]
    }
   ],
   "source": [
    "import classification_work\n",
    "importlib.reload(classification_work)\n",
    "\n",
    "#classification BEFORE EDA and attribute selection\n",
    "classification_work.classify_data(\"input_data/stroke-data-all-attributes-cleaned.csv\", random_seed)\n",
    "\n",
    "#TODO: attribute selection (based on EDA), analysis\n",
    "#TODO: flask web app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Provide a brief conclusion of your project, including a short summary of the dataset you used (and any of its inherent challenges for classification), the classification approach you developed, your classifiers’ performance, and any ideas you have on ways to improve its performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
