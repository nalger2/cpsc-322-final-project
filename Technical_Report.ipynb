{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from tabulate import tabulate\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable \n",
    "\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyKNeighborsClassifier, MyDummyClassifier, MyNaiveBayesClassifier, MyDecisionTreeClassifier\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_data/stroke-data.csv\n",
      "length before 'NA' values removed: 5110\n",
      "length after 'NA' values removed: 4909\n",
      "amount of non-strokes with no 'NA' rows: 4700\n",
      "amount of strokes with no 'NA' rows: 209\n",
      "length of downsized non-stroke data: 791\n",
      "length of all downsized data: 1000\n",
      "length of final_data 1000\n",
      "non-stroke amount: 791\n",
      "stroke amount: 209\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "import mysklearn.mypytable\n",
    "import os\n",
    "import copy\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "filename = os.path.join(\"input_data\", \"stroke-data.csv\")\n",
    "print(filename)\n",
    "table = mysklearn.mypytable.MyPyTable().load_from_file(filename)\n",
    "print(\"length before 'NA' values removed:\", len(table.data))\n",
    "\n",
    "table.remove_rows_with_missing_values()\n",
    "print(\"length after 'NA' values removed:\", len(table.data))\n",
    "\n",
    "# creating downsample data\n",
    "table_deep_copy = copy.deepcopy(table)\n",
    "\n",
    "non_stroke = []\n",
    "stroke_data = []\n",
    "for row in table.data:\n",
    "    if row[-1] == 0.0:\n",
    "        non_stroke.append(row)\n",
    "    if row[-1] == 1.0:\n",
    "        stroke_data.append(row)\n",
    "print(\"amount of non-strokes with no 'NA' rows:\", len(non_stroke))\n",
    "print(\"amount of strokes with no 'NA' rows:\", len(stroke_data))\n",
    "\n",
    "downsized_non_stroke_data = []\n",
    "for i in range(0, 1000 - len(stroke_data)):\n",
    "    index = np.random.randint(0, len(non_stroke))\n",
    "    row = non_stroke[index]\n",
    "    downsized_non_stroke_data.append(row)\n",
    "    non_stroke.remove(row)\n",
    "\n",
    "print(\"length of downsized non-stroke data:\", len(downsized_non_stroke_data))\n",
    "\n",
    "data_downsized = stroke_data + downsized_non_stroke_data # adding 1.0 class label and downsized 0.0 sample\n",
    "\n",
    "print(\"length of all downsized data:\", len(data_downsized)) # 1000 0 class labels, 209 1 class labels (after removal of 'NA' rows)\n",
    "\n",
    "final_data = table_deep_copy\n",
    "final_data.data = data_downsized\n",
    "print(\"length of final_data\", len(final_data.data))\n",
    "\n",
    "final_data.save_to_file(\"input_data/stroke-data-downsized.csv\")\n",
    "\n",
    "stroke_count = 0\n",
    "non_stroke_count = 0\n",
    "for row in final_data.data:\n",
    "    if row[-1] == 0.0:\n",
    "        non_stroke_count += 1\n",
    "    elif row[-1] == 1.0:\n",
    "        stroke_count += 1\n",
    "\n",
    "print(\"non-stroke amount:\", non_stroke_count)\n",
    "print(\"stroke amount:\", stroke_count)\n",
    "\n",
    "# checking if theres any duplicate rows # can delete loop\n",
    "for i in range(len(final_data.data)): \n",
    "    row = final_data.data[i]\n",
    "    for j in range(len(final_data.data)):\n",
    "        if row == final_data.data[j] and j != i:\n",
    "            print(\"same\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "\n",
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
