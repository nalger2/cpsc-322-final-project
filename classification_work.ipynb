{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification implementation code --- to be cleaned up and pasted into Technical Report\n",
    "\n",
    "import importlib\n",
    "from tabulate import tabulate\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable \n",
    "\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyKNeighborsClassifier, MyDummyClassifier, MyNaiveBayesClassifier #, MyDecisionTreeClassifier\n",
    "\n",
    "import mysklearn.myclassifier_maya\n",
    "importlib.reload(mysklearn.myclassifier_maya)\n",
    "from mysklearn.myclassifier_maya import MyDecisionTreeClassifier\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation\n",
    "\n",
    "random_state_val = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attribute names: ['id', 'gender', 'age', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'avg_glucose_level', 'bmi', 'smoking_status', 'stroke']\n",
      "len before removing missing vals 1000\n",
      "classes: [0.0, 1.0]\n",
      "num instances of class 0.0 : 791\n",
      "num instances of class 1.0 : 209\n"
     ]
    }
   ],
   "source": [
    "#loading data\n",
    "stroke_data = MyPyTable()\n",
    "stroke_data.load_from_file(\"input_data/stroke-data-downsized.csv\")\n",
    "print(\"attribute names:\", stroke_data.column_names)\n",
    "print(\"len before removing missing vals\", len(stroke_data.data))\n",
    "\n",
    "#code to remove rows w/missing values (use only once relevant attributes are decided)\n",
    "#stroke_data.remove_rows_with_missing_values()\n",
    "#stroke_data.remove_rows_with_missing_values_by_col()\n",
    "#print(\"len after removing missing vals\", len(stroke_data.data))\n",
    "\n",
    "#code to group data by class\n",
    "stroke_classes, stroke_data_by_class = myutils.group_by(stroke_data.data, stroke_data.column_names, \"stroke\")\n",
    "print(\"classes:\", stroke_classes)\n",
    "for partition in stroke_data_by_class:\n",
    "    print(\"num instances of class\", partition[0][-1], \":\", len(partition))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make classifiers - KNN, NB, DT, RF\n",
    "knn_clf = MyKNeighborsClassifier(n_neighbors=5)\n",
    "nb_clf = MyNaiveBayesClassifier()\n",
    "tree_clf = MyDecisionTreeClassifier()\n",
    "#TODO: random forest\n",
    "\n",
    "#clean stroke data for classification- discretize, convert nominal to numeric\n",
    "stroke_data_discretized = myutils.discretize_attributes_for_stroke_classification(stroke_data)\n",
    "stroke_data_discretized.save_to_file(\"input_data/stroke-data-discretized.csv\")\n",
    "\n",
    "#strings to numeric\n",
    "stroke_data_cleaned_numeric = myutils.numerize_all_strings(stroke_data_discretized)\n",
    "stroke_data_cleaned_numeric.save_to_file(\"input_data/stroke-data-cleaned-numeric.csv\")\n",
    "\n",
    "# ATTRIBUTE SELECTION - BASED ON EDA RESULTS\n",
    "\n",
    "\n",
    "#Create X and y data\n",
    "X = [inst[:-1] for inst in stroke_data_cleaned_numeric.data]\n",
    "y = [inst[-1] for inst in stroke_data_cleaned_numeric.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k fold cross validation\n",
    "knn_y_pred = []\n",
    "nb_y_pred = []\n",
    "tree_y_pred = []\n",
    "#forest_y_pred = []\n",
    "\n",
    "y_true = []\n",
    "X_train_folds, X_test_folds = myevaluation.kfold_cross_validation(X, n_splits=10, random_state=random_state_val, shuffle=True)\n",
    "for fold_index in range(len(X_train_folds)): \n",
    "    X_train, y_train, X_test, y_test = myutils.one_fold_splits(X, y, X_train_folds, X_test_folds, fold_index)\n",
    "    #build y true\n",
    "    for val in y_test:\n",
    "        y_true.append(val)\n",
    "   \n",
    "    #fit and predict kNN classifier\n",
    "    knn_clf.fit(X_train, y_train)\n",
    "    for pred in knn_clf.predict(X_test):\n",
    "        knn_y_pred.append(pred) \n",
    "   \n",
    "   #fit and predict naive bayes\n",
    "    nb_clf.fit(X_train, y_train)\n",
    "    for pred in nb_clf.predict(X_test):\n",
    "        nb_y_pred.append(pred)\n",
    "   \n",
    "   #fit and predict tree    #TODO ASK ABOUT THIS ERROR MESSAGE\n",
    "    tree_clf.fit(X_train, y_train)\n",
    "    for pred in tree_clf.predict(X_test):\n",
    "        tree_y_pred.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision 734 / 925 0.7935135135135135\n",
      "recall 734 / 791 0.9279393173198482\n",
      "precision 734 / 925 0.7935135135135135\n",
      "recall 734 / 791 0.9279393173198482\n",
      "\n",
      "=====================\n",
      "kNN Classifier (5 neighbors)\n",
      "=====================\n",
      "Accuracy:\t 0.75\n",
      "Error Rate:\t 0.25\n",
      "Precision:\t 0.79\n",
      "Recall:\t\t 0.93\n",
      "F1 measure:\t 0.86\n",
      "Confusion matrix:\n",
      "       0.0    1.0\n",
      "--  -----  -----\n",
      " 0    734     57\n",
      " 1    191     18\n",
      "precision 789 / 998 0.7905811623246493\n",
      "recall 789 / 791 0.9974715549936789\n",
      "precision 789 / 998 0.7905811623246493\n",
      "recall 789 / 791 0.9974715549936789\n",
      "\n",
      "=====================\n",
      "Naive Bayes\n",
      "=====================\n",
      "Accuracy:\t 0.79\n",
      "Error Rate:\t 0.21\n",
      "Precision:\t 0.79\n",
      "Recall:\t\t 1.0\n",
      "F1 measure:\t 0.88\n",
      "Confusion matrix:\n",
      "       0.0    1.0\n",
      "--  -----  -----\n",
      " 0    789      2\n",
      " 1    209      0\n",
      "precision 787 / 996 0.7901606425702812\n",
      "recall 787 / 791 0.9949431099873578\n",
      "precision 787 / 996 0.7901606425702812\n",
      "recall 787 / 791 0.9949431099873578\n",
      "\n",
      "=====================\n",
      "Decision Tree\n",
      "=====================\n",
      "Accuracy:\t 0.79\n",
      "Error Rate:\t 0.21\n",
      "Precision:\t 0.79\n",
      "Recall:\t\t 0.99\n",
      "F1 measure:\t 0.88\n",
      "Confusion matrix:\n",
      "       0.0    1.0\n",
      "--  -----  -----\n",
      " 0    787      4\n",
      " 1    209      0\n"
     ]
    }
   ],
   "source": [
    "predictions = [knn_y_pred, nb_y_pred, tree_y_pred] #TODO add tree, forest results\n",
    "titles = [\"kNN Classifier (5 neighbors)\", \"Naive Bayes\", \"Decision Tree\"]\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    myutils.show_results(y_true, predictions[i], stroke_classes, titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
