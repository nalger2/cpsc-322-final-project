{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification implementation code --- to be cleaned up and pasted into Technical Report\n",
    "\n",
    "import importlib\n",
    "from tabulate import tabulate\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable \n",
    "\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyKNeighborsClassifier, MyDummyClassifier, MyNaiveBayesClassifier, MyDecisionTreeClassifier\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attribute names: ['id', 'gender', 'age', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'avg_glucose_level', 'bmi', 'smoking_status', 'stroke']\n",
      "len before removing missing vals 1000\n",
      "classes: [0.0, 1.0]\n",
      "num instances of class 0.0 : 791\n",
      "num instances of class 1.0 : 209\n"
     ]
    }
   ],
   "source": [
    "#loading data\n",
    "stroke_data = MyPyTable()\n",
    "stroke_data.load_from_file(\"input_data/stroke-data-downsized.csv\")\n",
    "print(\"attribute names:\", stroke_data.column_names)\n",
    "print(\"len before removing missing vals\", len(stroke_data.data))\n",
    "\n",
    "#code to remove rows w/missing values (use only once relevant attributes are decided)\n",
    "#stroke_data.remove_rows_with_missing_values()\n",
    "#stroke_data.remove_rows_with_missing_values_by_col()\n",
    "#print(\"len after removing missing vals\", len(stroke_data.data))\n",
    "\n",
    "#code to group data by class\n",
    "stroke_classes, stroke_data_by_class = myutils.group_by(stroke_data.data, stroke_data.column_names, \"stroke\")\n",
    "print(\"classes:\", stroke_classes)\n",
    "for partition in stroke_data_by_class:\n",
    "    print(\"num instances of class\", partition[0][-1], \":\", len(partition))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'gender', 'age', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'avg_glucose_level', 'bmi', 'smoking_status', 'stroke'] \n",
      " [9046.0, 'Male', 67.0, 0.0, 1.0, 'Yes', 'Private', 'Urban', 228.69, 36.6, 'formerly smoked', 1.0]\n",
      "['gender', 'age', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'avg_glucose_level', 'bmi', 'smoking_status', 'stroke'] \n",
      " ['Male', 6.0, 0.0, 1.0, 'Yes', 'Private', 'Urban', 5, 3.0, 'formerly smoked', 1.0]\n"
     ]
    }
   ],
   "source": [
    "#make classifiers - KNN, NB, DT, RF\n",
    "knn_clf = MyKNeighborsClassifier(n_neighbors=5)\n",
    "nb_clf = MyNaiveBayesClassifier()\n",
    "dt_clf = MyDecisionTreeClassifier()\n",
    "#TODO: random forest\n",
    "\n",
    "#TODO clean stroke data for classification- discretize, convert nominal to numeric\n",
    "print(stroke_data.column_names, \"\\n\", stroke_data.data[0])\n",
    "stroke_data_discretized = myutils.discretize_attributes_for_stroke_classification(stroke_data)\n",
    "print(stroke_data_discretized.column_names, \"\\n\", stroke_data_discretized.data[0])\n",
    "#save discretized to file\n",
    "stroke_data_discretized.save_to_file(\"input_data/stroke-data-discretized.csv\")\n",
    "\n",
    "#strings to numeric\n",
    "stroke_data_cleaned_numeric = myutils.numerize_all_strings(stroke_data_discretized)\n",
    "stroke_data_cleaned_numeric.save_to_file(\"input_data/stroke-data-cleaned-numeric.csv\")\n",
    "\n",
    "#Create xtrain/ytrains (TODO change to stratified k fold later)\n",
    "X_train = [inst[:-1] for inst in stroke_data_discretized.data]\n",
    "y_train = [inst[-1] for inst in stroke_data_discretized.data]\n",
    "\n",
    "#TODO fit and predict classifiers\n",
    "\n",
    "#TODO Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
