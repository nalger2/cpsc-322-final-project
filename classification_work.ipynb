{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification implementation code --- to be cleaned up and pasted into Technical Report\n",
    "\n",
    "import importlib\n",
    "from tabulate import tabulate\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable \n",
    "\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyKNeighborsClassifier, MyDummyClassifier, MyNaiveBayesClassifier, MyDecisionTreeClassifier\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation\n",
    "\n",
    "random_state_val = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attribute names: ['id', 'gender', 'age', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'avg_glucose_level', 'bmi', 'smoking_status', 'stroke']\n",
      "len before removing missing vals 1000\n",
      "classes: [0.0, 1.0]\n",
      "num instances of class 0.0 : 791\n",
      "num instances of class 1.0 : 209\n"
     ]
    }
   ],
   "source": [
    "#loading data\n",
    "stroke_data = MyPyTable()\n",
    "stroke_data.load_from_file(\"input_data/stroke-data-downsized.csv\")\n",
    "print(\"attribute names:\", stroke_data.column_names)\n",
    "print(\"len before removing missing vals\", len(stroke_data.data))\n",
    "\n",
    "#code to remove rows w/missing values (use only once relevant attributes are decided)\n",
    "#stroke_data.remove_rows_with_missing_values()\n",
    "#stroke_data.remove_rows_with_missing_values_by_col()\n",
    "#print(\"len after removing missing vals\", len(stroke_data.data))\n",
    "\n",
    "#code to group data by class\n",
    "stroke_classes, stroke_data_by_class = myutils.group_by(stroke_data.data, stroke_data.column_names, \"stroke\")\n",
    "print(\"classes:\", stroke_classes)\n",
    "for partition in stroke_data_by_class:\n",
    "    print(\"num instances of class\", partition[0][-1], \":\", len(partition))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make classifiers - KNN, NB, DT, RF\n",
    "knn_clf = MyKNeighborsClassifier(n_neighbors=5)\n",
    "nb_clf = MyNaiveBayesClassifier()\n",
    "tree_clf = MyDecisionTreeClassifier()\n",
    "#TODO: random forest\n",
    "\n",
    "#clean stroke data for classification- discretize, convert nominal to numeric\n",
    "stroke_data_discretized = myutils.discretize_attributes_for_stroke_classification(stroke_data)\n",
    "stroke_data_discretized.save_to_file(\"input_data/stroke-data-discretized.csv\")\n",
    "\n",
    "#strings to numeric\n",
    "stroke_data_cleaned_numeric = myutils.numerize_all_strings(stroke_data_discretized)\n",
    "stroke_data_cleaned_numeric.save_to_file(\"input_data/stroke-data-cleaned-numeric.csv\")\n",
    "\n",
    "#Create X and y data\n",
    "X = [inst[:-1] for inst in stroke_data_cleaned_numeric.data]\n",
    "y = [inst[-1] for inst in stroke_data_cleaned_numeric.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k fold cross validation\n",
    "knn_y_pred = []\n",
    "nb_y_pred = []\n",
    "tree_y_pred = []\n",
    "#forest_y_pred = []\n",
    "\n",
    "y_true = []\n",
    "X_train_folds, X_test_folds = myevaluation.kfold_cross_validation(X, n_splits=10, random_state=random_state_val, shuffle=True)\n",
    "for fold_index in range(len(X_train_folds)): \n",
    "    X_train, y_train, X_test, y_test = myutils.one_fold_splits(X, y, X_train_folds, X_test_folds, fold_index)\n",
    "    #build y true\n",
    "    for val in y_test:\n",
    "        y_true.append(val)\n",
    "   \n",
    "    #fit and predict kNN classifier\n",
    "    knn_clf.fit(X_train, y_train)\n",
    "    for pred in knn_clf.predict(X_test):\n",
    "        knn_y_pred.append(pred) \n",
    "   \n",
    "   #fit and predict naive bayes\n",
    "    nb_clf.fit(X_train, y_train)\n",
    "    for pred in nb_clf.predict(X_test):\n",
    "        nb_y_pred.append(pred)\n",
    "   \n",
    "   #fit and predict tree    #TODO ASK ABOUT THIS ERROR MESSAGE\n",
    "    #tree_clf.fit(X_train, y_train)\n",
    "    #for pred in tree_clf.predict(X_test):\n",
    "    #    tree_y_pred.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================\n",
      "kNN Classifier (5 neighbors)\n",
      "=====================\n",
      "Accuracy:\t 0.74\n",
      "Error Rate:\t 0.26\n",
      "Precision:\t 0.78\n",
      "Recall:\t\t 0.93\n",
      "F1 measure:\t 0.85\n",
      "Confusion matrix:\n",
      "       0.0    1.0\n",
      "--  -----  -----\n",
      " 0    739     52\n",
      " 1    204      5\n",
      "\n",
      "=====================\n",
      "Naive Bayes\n",
      "=====================\n",
      "Accuracy:\t 0.79\n",
      "Error Rate:\t 0.21\n",
      "Precision:\t 0.79\n",
      "Recall:\t\t 1.0\n",
      "F1 measure:\t 0.88\n",
      "Confusion matrix:\n",
      "       0.0    1.0\n",
      "--  -----  -----\n",
      " 0    791      0\n",
      " 1    209      0\n"
     ]
    }
   ],
   "source": [
    "predictions = [knn_y_pred, nb_y_pred] #TODO add tree, forest results\n",
    "titles = [\"kNN Classifier (5 neighbors)\", \"Naive Bayes\"]\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    myutils.show_results(y_true, predictions[i], stroke_classes, titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
